{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 9.4 Convolution and Pooling as an Infinitely Strong Prior\n",
    "\n",
    "### pp. 347 pooling and convolution are just assumptions; and assumptions can fail.\n",
    "\n",
    "> One key insight is that convolution and pooling can cause underfitting. Like any prior, convolution and pooling are only useful when the assumptions made by the prior are reasonably accurate. If a task relies on preserving precise spatial information, then using pooling on all features can increase the training error. Some convolutional network architectures (Szegedy et al., 2014a) are designed to use pooling on some channels but not on other channels, in order to get both highly invariant features and features that will not underfit when the translation invariance prior is incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 9.5 Variants of the Basic Convolution Function\n",
    "\n",
    "### pp. 349 amount of padding should be appropriate\n",
    "\n",
    "> Usually the optimal amount of zero padding (in terms of test set classification accuracy) lies somewhere between “valid” and “same” convolution.\n",
    "\n",
    "### pp. 357 output size of convolution transpose can be ambiguous.\n",
    "\n",
    "> In some cases, multiple sizes of input to forward propagation can result in the same size of output map, so the transpose operation must be explicitly told what the size of the original input was.\n",
    "\n",
    "### pp. 358 separating bias values at different locations may help. although I don't see people do that in practice (at least DL frameworks don't allow that).\n",
    "\n",
    "> Separating the biases may slightly reduce the statistical efficiency of the model, but also allows the model to correct for differences in the image statistics at different locations. For example, when using implicit zero padding, detector units at the edge of the image receive less total input and may need larger biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 9.9 Random or Unsupervised Features\n",
    "\n",
    "Not sure how these methods work in practice, as references here are mostly before 2013.\n",
    "\n",
    "In [How transferable are features in deep neural networks?](papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks), they found that random weights don't work for ImageNet, and they give some reasoning on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 9.10 The Neuroscientific Basis for Convolutional Networks\n",
    "\n",
    "### pp. 367 deep learning involving attention, saccade, and foveation.\n",
    "\n",
    "> In the context of deep learning, attention mechanisms have been most successful for natural language processing, as described in section 12.4.5.1. Several visual models with foveation mechanisms have been developed but so far have not become the dominant approach (Larochelle and Hinton, 2010; Denil et al., 2012).\n",
    "\n",
    "### pp. 367 simple cells are complex cells are not different inherently.\n",
    "\n",
    "> Indeed our cartoon picture of “simple cells” and “complex cells” might create a nonexistent distinction; simple cells and complex cells might both be the same kind of cell but with their “parameters” enabling a continuum of behaviors ranging from what we call “simple” to what we call “complex.”\n",
    "\n",
    "### pp. 369 check end of this page, seems that this is the only place where sqrt is in complex cell response.\n",
    "\n",
    "Actually I think this make more sense, as this will make the response magnitude somehow more linear, similar to simple cell. Well, you can also make simple cell's response to be squared, instead of linear (actually this is what's done in Rust's paper [Spatiotemporal Elements of Macaque V1 Receptive Fields](http://dx.doi.org/10.1016/j.neuron.2005.05.021))\n",
    "\n",
    "### pp. 370 many algorithms can learn Gabor.\n",
    "\n",
    "> Because so many different learning algorithms learn edge detectors, it is difficult to conclude that any specific learning algorithm is the“right” model of the brain just based on the features that it learns (though it can certainly be a bad sign if an algorithm does not learn some sort of edge detector when applied to natural images)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

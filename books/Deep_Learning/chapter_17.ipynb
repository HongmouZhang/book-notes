{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 17.0\n",
    "\n",
    "### pp. 590 Approximate method is our only choice.\n",
    "\n",
    "> Many problems in machine learning are so difficult that we can never expect to obtain precise answers to them. This excludes precise deterministic algorithms and Las Vegas algorithms. Instead, we must use deterministic approximate algorithms or Monte Carlo approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 17.1 Sampling and Monte Carlo Methods\n",
    "\n",
    "### pp. 592 two basic approaches to sampling\n",
    "\n",
    "> However, all this relies on our ability to easily sample from the base distribution p(x), but doing so is not always possible. When it is not feasible to sample from $p$, an alternative is to use importance sampling, presented in section 17.2. A more general approach is to form a sequence of estimators that converge towards the distribution of interest. That is the approach of Monte Carlo Markov chains (section 17.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 17.2 Importance Sampling\n",
    "\n",
    "### pp. 594 biased importance sampling\n",
    "\n",
    "> This estimator is biased because $E[\\hat{s}_{BIS}] \\ne s$, except asymptotically when $n \\rightarrow \\infty$ and the denominator of equation 17.14 converges to 1\n",
    "\n",
    "The proof that it will finally be consistent can be seen in pp. 20 of <http://www.cs.cmu.edu/~rsalakhu/10807_2016/Lectures/Lecture_MCMC.pdf>, copied [here](./chapter_17/biased_importance_sampling.pdf). A similar proof is also given in Chapter 11 of PRML.\n",
    "\n",
    "I think it should be biased, because there's correlation between numerator and denominator. I think the product (or ratio) of two unbiased yet correlated stuff probably would yield biased results.\n",
    "\n",
    "\n",
    "Main problem of importance sampling is that if $q(x)$ miss regions that $p(x)$ is high, then the estimate would be very wrong, and that this problem is probably inevitable in high dimensionality. This is also mentioned by PRML, in 11.1.4 and start of 11.2.\n",
    "\n",
    "> Although a good choice of q can greatly improve the efficiency of Monte Carlo estimation, a poor choice of q can make the efficiency much worse. \n",
    "\n",
    "> When x is high-dimensional, this simplicity in q causes it to match $p$ or $p|f|$ poorly. When ... , importance sampling collects useless samples (summing tiny numbers or zeros). On the other hand, when ... which will happen more rarely, the ratio can be huge. Because these latter events are rare, they may not show up in a typical sample, yielding typical underestimation of $s$, compensated rarely by gross overestimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.4 Gibbs sampling\n",
    "\n",
    "### pp. 599 two approaches to transition probability\n",
    "\n",
    "> Two basic approaches are considered in this book.The first one is to derive T from a given learned $p_{model}$, described below with thecase of sampling from EBMs. The second one is to directly parametrize T andlearn it, so that its stationary distribution implicitly defines the $p_{model}$ of interest. Examples of this second approach are discussed in sections 20.12 and 20.13.\n",
    "\n",
    "The second approach sounds exciting.\n",
    "\n",
    "### pp. 599 people use nothing else than Gibbs sampling. Perhaps other methods don't give improvement?\n",
    "\n",
    "> In the context of the deep learning approach to undirected modeling, it is rare to use any approach other than Gibbs sampling. Improved sampling techniques are one possible research frontier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5 The Challenge of Mixing between Separated Modes\n",
    "\n",
    "### pp. 602 poor mixing of MCMC is harmful, and sometimes our training goal will encourage poor mixing.\n",
    "\n",
    "> In the context of models with latent variables, which define a joint distribution $p_{model}(x, h)$, we often draw samples of $x$ by alternating between sampling from $p_{model}(x \\mid h)$ and sampling from $p_{model}(h \\mid x)$. From the point view of mixing rapidly, ... However, from the point of view of learning a useful representation ... These two goals are at odds with each other. We often learn generative models that very precisely encode x into h but are not able to mix very well. This situation arises frequently with Boltzmann machines\n",
    "\n",
    "Check Fig. 17.2. Seems that having no mixing problem is important.\n",
    "\n",
    "### pp. 603 tempering can help to mix faster. But seems not successful yet.\n",
    "\n",
    "> Although tempering is a promising approach, at this point it has not allowed researchers to make a strong advance in solving the challenge of sampling from complex EBMs. One possible reason is that there are critical temperatures around which the temperature transition must be very slow (as the temperature is gradually reduced) in order for tempering to be effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

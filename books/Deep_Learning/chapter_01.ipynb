{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pp. 4\n",
    "\n",
    "> When designing features or algorithms for learning features, our goal is usually to separate the factors of variation that explain the observed data.\n",
    "\n",
    "top principle for designing feature.\n",
    "\n",
    "### pp. 5-7\n",
    "\n",
    "> The idea of learning the right representation for the data provides one perspective on deep learning. Another perspective on deep learning is that depth allows the computer to learn a multi-step computer program. ... It has nothing to do with the content of the input specifically, but it helps the model to organize its processing.\n",
    "\n",
    "From this perspective, some layers are simply needed for some steps in processing, not corresponding to more complex representations of the feature.\n",
    "\n",
    "### pp. 10\n",
    "\n",
    "Figure 1.5 shows the differences between different machine learning (or in general, AI) approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Historical Trends in Deep Learning\n",
    "\n",
    "### pp. 16 connection with neuroscience\n",
    "\n",
    "> This suggests that much of the mammalian brain might use a single algorithm to solve most of the different tasks that the brain solves.\n",
    "\n",
    "> We know that actual neurons compute very different functions than modern rectified linear units, but greater neural realism has not yet led to an improvement in machine learning performance. Also, while neuroscience has successfully inspired several neural network architectures, we do not yet know enough about biological learning for neuroscience to offer much guidance for the learning algorithms we use to train these architectures.\n",
    "\n",
    "> While some deep learning researchers cite neuroscience as an important source of inspiration, others are not concerned with neuroscience at all.\n",
    "\n",
    "### pp. 20 big data means learning easier\n",
    "\n",
    "> The age of “Big Data” has made machine learning much easier because the key burden of statistical estimation—generalizing well to new data after observing only a small amount of data—has been considerably lightened.\n",
    "\n",
    "### pp. 25 the ultimate neural network model\n",
    "\n",
    "> This trend of increasing complexity has been pushed to its logical conclusion with the introduction of neural Turing machines ... This self-programming technology is in its infancy, but in the future could in principle be applied to nearly any task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

%!TEX program = xelatex
%!TEX encoding = UTF-8 412-268-2097Unicode

\documentclass[12pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}

% Will Robertson's fontspec.sty can be used to simplify font choices.
% To experiment, open /Applications/Font Book to examine the fonts provided on Mac OS X,
% and change "Hoefler Text" to any of these choices.

\usepackage{fontspec,xltxtra,xunicode}

\newcommand{\vect}[1]{\boldsymbol{#1}}

\defaultfontfeatures{Mapping=tex-text}
\setromanfont[Mapping=tex-text]{Hoefler Text}
\setsansfont[Scale=MatchLowercase,Mapping=tex-text]{Gill Sans}
\setmonofont[Scale=MatchLowercase]{Andale Mono}

\title{Brief Article}
\author{The Author}
%\date{}                                           % Activate to display a given date or no date

\begin{document}
\maketitle

% For many users, the previous commands will be enough.
% If you want to directly input Unicode, add an Input Menu or Keyboard to the menu bar 
% using the International Panel in System Preferences.
% Unicode must be typeset using a font containing the appropriate characters.
% Remove the comment signs below for examples.

% \newfontfamily{\A}{Geeza Pro}
% \newfontfamily{\H}[Scale=0.9]{Lucida Grande}
% \newfontfamily{\J}[Scale=0.85]{Osaka}

% Here are some multilingual Unicode fonts: this is Arabic text: {\A السلام عليكم}, this is Hebrew: {\H שלום}, 
% and here's some Japanese: {\J 今日は}.

\section{EM with prior on $\vect{\theta}$} % (fold)
\label{sec:em_with_prior_on_boldsymbol_}

On pp. 454 of PRML, we have an expression for $\ln p(\vect{\theta}\mid X)$. Let's derive it.
\begin{align}
p(\vect{\theta}\mid X) & = \frac{\sum_Z p(\vect{\theta},Z,X)}{p(X)}  \\
                       & = \frac{\sum_Z p(Z,X\mid \vect{\theta}) p(\vect{\theta}) }{p(X)},\\
\ln p(\vect{\theta}\mid X)   & = p(X\mid \theta) + \ln p(\vect{\theta}) - \ln p(X)\\
                             & = L(q,\vect{\theta}) + \mathrm{KL}(q \| p) + \ln p(\vect{\theta}) - \ln p(X).              
\end{align}

% section em_with_prior_on_boldsymbol_ (end)





\section{9.12} % (fold)
\label{sec:9_12}

Basically, the idea is to represent mean and covariance in terms of moments.

\begin{align}
E(\vect{x} ) & = \sum_{\vect{x}} \sum_{k=1}^K \pi_k p(\vect{x}\mid k) \vect{x} \\
             & =  \sum_{k=1}^K \pi_k \sum_{\vect{x}} p(\vect{x}\mid k) \vect{x} \\
             & = \sum_{k=1}^K \pi_k \vect{\mu}_k, \\
\mathrm{cov}(\vect{x}) & = \sum_{\vect{x}}  \sum_{k=1}^K \pi_k p(\vect{x}\mid k)  \vect{x} \vect{x}^T - E(\vect{x} ) E(\vect{x} )^T \\
             & = \sum_{k=1}^K \pi_k \sum_{\vect{x}} p(\vect{x}\mid k) \vect{x} \vect{x}^T - E(\vect{x} ) E(\vect{x} )^T \\
             & = \sum_{k=1}^K \pi_k [ \Sigma_k + \vect{\mu}_k \vect{\mu}_k^T ] - E(\vect{x} ) E(\vect{x} )^T
\end{align}

% section 9_12 (end)


\section{9.15} % (fold)
\label{sec:9_15}
Taking the derivative of expected complete data log likelihood w.r.t. $\mu_{k,i}$ and set it to zero, we have

\begin{align}
\frac{\partial L}{\partial \mu_{k,i} } & = \sum_{n=1}^N \gamma_{n,k} \left[ \frac{x_{n,i}}{\mu_{k,i}} - \frac{1-x_{n,i}}{1-\mu_{k,i}} \right] \\
        & = 0, \\
     0  & =  \sum_{n=1}^N \gamma_{n,k} \left[ \frac{x_{n,i}}{\mu_{k,i}} - \frac{1-x_{n,i}}{1-\mu_{k,i}} \right] [\mu_{k,i}(1-\mu_{k,i})] \\
        & = \sum_{n=1}^N \gamma_{n,k} \left[ x_{n,i} (1-\mu_{k,i}) - (1-x_{n,i})\mu_{k,i} \right] \\
        & = \sum_{n=1}^N \gamma_{n,k} \left[ x_{n,i}- \mu_{k,i} \right], \\
    \mu_{k,i} & =  \frac{\sum_{n=1}^N    \gamma_{n,k} x_{n,i}}{\sum_{n=1}^N    \gamma_{n,k}} 
\end{align}

Doing this for every i, then arrange them into a vector, we have desired result.

% section 9_15 (end) 


\section{9.24} % (fold)
\label{sec:9_24}

\begin{align}
\ln p(X,Z\mid \vect{\theta}) & = \ln p(Z\mid X, \vect{\theta}) + \ln(X\mid \vect{\theta}),\\
L(q,\vect{\theta}) & = \sum_Z q(Z) \ln p(X,Z\mid \vect{\theta}) - \sum_Z q(Z) \ln q(Z) \\
                   & = \sum_Z q(Z) [   \ln p(Z\mid X, \vect{\theta}) + \ln(X\mid \vect{\theta})  ] - \sum_Z q(Z) \ln q(Z)\\
                   & = \sum_Z q(Z) [\ln p(Z\mid X, \vect{\theta}) - \ln q(Z)] + \sum_Z q(Z) \ln(X\mid \vect{\theta}) \\
                   & = -\mathrm{KL}(q \| p) + \ln(X\mid \vect{\theta}).
\end{align}

% section 9_24 (end)

\end{document}  
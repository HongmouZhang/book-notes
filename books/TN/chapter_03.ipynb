{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notes for Chapter 3 of *Theoretical Neuroscience* by P. Dayan and L. F. Abbott."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Discrimination\n",
    "\n",
    "This sections establishes the importance of ROC curve, and two-alternative forced choice experiment design.\n",
    "\n",
    "For more interpretation on area of RUC, see [this stackexchange page](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it) [local version](./chapter_03/auroc.htm)\n",
    "\n",
    "all the math derivations in this section all make sense, although my rusty memory of calculus doesn't allow me to fully verify them. There might be some missing assumptions, etc., but they all intuitively make sense.\n",
    "\n",
    "### pp. 94 ROC interpretation under two-alternative forced-choice test.\n",
    "\n",
    "> Thus, the area under the ROC curve is the probability of responding correctly in the two-alternative forced-choice test.\n",
    "\n",
    "### pp. 94 d-prime\n",
    "\n",
    "> It is common to quote $d'$ values even for non-Gaussian distributions by inverting the relationship between $P[\\mathrm{correct}]$ and $d'$ in equation 3.10.\n",
    "\n",
    "### pp. 95 simulation of two-alternative forced-choice task.\n",
    "\n",
    "the anti-neuron is just a random sample of response for the other class. It's consistent with the previous stackexchange page: \"The expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative\".\n",
    "\n",
    "it's interesting why one neuron can perform this well. There are some explanations.\n",
    "\n",
    "> One speculation is that correlations in the response variability between neurons limit the performance of the monkey.\n",
    "\n",
    "### pp. 95 likelihood ratio test.\n",
    "\n",
    "in previous discussion, the score function used for classification is the firing rate itself, and we use score to compare against some threshold to make decision. By using different threshold, we get trade off between $\\alpha$ and $\\beta$. However, there's possibility that we may use some other function of $r$ as score function to get better trade off of $\\alpha$ and $\\beta$. Here, the authors show that among all classification procedures using score function of $r$ and some threshold, likelihood ratio test is the best.\n",
    "\n",
    "In this particular study, likelihood ratio and $r$ itself has a monotonic relationship. Thus they are equally powerful. However, this is not necessarily true.\n",
    "\n",
    "### pp. 96 Eq. (3.14) ratio and ROC.\n",
    "\n",
    "This relationship always holds; this doesn't say that $r$ itself is always same as using ratio. It can be the case that for different $r$ we have the same ratio.\n",
    "\n",
    "### pp. 96 Eq. (3.15) and Eq. (3.16) derivation of ratio test from a Bayesian perspective.\n",
    "\n",
    "### pp. 97 Eq. (3.18) score function for continuous value discrimination.\n",
    "\n",
    "this is closely related to fisher information. Check Eq. (3.43)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Population Coding\n",
    "\n",
    "### pp. 100 caveats in cosine tuning curve for M1 neurons.\n",
    "\n",
    "> Of course, these neurons encode additional movement-related quantities; for example, their firing rates depend on the initial position of the arm relative to the body as well as on movement velocity and acceleration. This complicates the interpretation of their activity as reporting movement direction in a particular coordinate system.\n",
    "\n",
    "Indeed M1 neuron should also encode other quantitities, other than movement direction, such as speed, etc.\n",
    "\n",
    "I asked Xiao Zhou, a PhD student of Steve Chase, about this. He said in his experiment settings, all these additional quantities, such as velocity, posture of monkey, etc., are usually kept constant during recording. He also tried comparing the tuning under different settings of these additional quantities, the tunings indeed changed, but they were still cosine.\n",
    "\n",
    "### pp. 101 naive vector method (Eq. (3.22)) decoding can be wrong.\n",
    "\n",
    "> Instead, the preferred directions of the neurons appear to point in all directions with roughly equal probability. If the projection axes are not orthogonal, the Cartesian sum of equation 3.22 is not the correct way to reconstruct $\\vec{v}$.\n",
    "\n",
    "Essentially, this vector method is doing linear projection and getting back the original coordinates. When directions are orthogonal, reconstruction is easy.\n",
    "\n",
    "However, as said below, if there are many neurons and directions are random uniformly, then this vector method is still roughly correct.\n",
    "\n",
    "### pp. 103 different loss functions lead to different optimal Bayesian inference result.\n",
    "\n",
    "Square error leads to mean, and absolute value leads to median. Check Ex. (1.27) and Eq. (1.91) of PRML for similar results.\n",
    "\n",
    "### pp. 103 Figure 3.7 Bayesian can be worse than ML because model is wrong.\n",
    "\n",
    "Notice that there's no absolute better method between Bayesian and ML on this dataset. However, since error is measured using square loss, and Baeysian model is trained to minimize this, Bayesian should outperform ML always.\n",
    "\n",
    "This didn't happen because they used real data to evaluate, and real data, with noise, were not Gaussian or cosine or distributed according to any simple distribution. So the model is wrong. Notice that in vector method, they use cosine. In Byesian and ML, they use Gaussian.\n",
    "\n",
    "> For the cercal interneurons, the response probability density $p[\\mathbf{r}|s]$ is a product of four Gaussians with means and variances given by the data points and error bars in figure 3.4.\n",
    "\n",
    "### pp. 108 Eq. (3.40) bias variance decomposition.\n",
    "\n",
    "Check Eqs. (3.41)-(3.44) in PRML. There we have noise term, as there's some additional noise from data to label.\n",
    "\n",
    "### pp. 109 Eqs. (3.42) and (3.43) they are not always the same.\n",
    "\n",
    "Check Section 7.4 \"Information and Efficiency\" of *Modern Mathematical Statistics with Applications, 2nd edition* by Jay L. Devore and Kenneth N. Berk. There are certain technical assumptions for this to hold. However, I believe they are most of the time satisified.\n",
    "\n",
    "### pp. 109 Eq. (3.41)\n",
    "\n",
    "notice that left side is variance. not total square error. So we can easily make variance small, but overall the error will be big. For example, if real $s$ is between 0 and 1, and we have an estimator that always give 0.5. It will have variance of 0, reaching the bound ($b'=-1$ in this case). However, it will have high bias almost for every actual $s$, resulting in high total square error.\n",
    "\n",
    "### pp. 110 Fisher Information is local and the bound can be loose (too low).\n",
    "\n",
    "> The Fisher information is purely local in the sense that it does not reflect the existence of stimulus values completely different from s that are likely to evoke the same responses as those evoked by $s$ itself. However, this does not happen for the sort of simple population codes we consider. Shannon's mutual information measure, discussed in chapter 4, takes such possibilities into account.\n",
    "\n",
    "Suppose $s$ can take values between 0 and 10. and $p[r|s]$ is same for $s \\in [0, 1]$, $s \\in [1,2]$, $s \\in [2,3]$, ..., $s \\in [9,10]$. By locality of Fisher information, the fisher information at 0.5 won't change, if we restrict $s$ to $[0,1]$ instead. Clearly, we can see that, in the case $s \\in [0, 10]$, we can't possibly achieve CramÃ©r-Rao lower bound simulatenously for all $s$, due to ambiguity in $p[r|s]$, and we may be able to, in the case $s \\in [0,1]$. This nonlocal issue is not considered by Fisher information.\n",
    "\n",
    "### pp. 110. Eq. (3.44)\n",
    "\n",
    "> If we assume that the array of tuning curves is symmetric, like the Gaussian array of figure 3.8, the second term in the parentheses of the last expression sums to 0.\n",
    "\n",
    "Check errata. it says if during derivation we use exact version (not Eq. (3.31), but Eq. (3.30)), then even if tuning curve is not symmetric, we still get the second term sum being 0. I haven't verified this claim.\n",
    "\n",
    "### pp. 111\n",
    "\n",
    "I find text here confusing.\n",
    "\n",
    "> Equation 3.45 indicates that the Fisher information will be largest if the tuning curves of individual neurons are rapidly varying (making the square of their derivatives large), and if many neurons respond (making the sum over neurons large).\n",
    "\n",
    "I don't understand why Eq. (3.45) needs many neurons to respond to be big. I think neuron response level should be low, yet change rate needs to be high.\n",
    "\n",
    "Later on they do some analysis on tuning width. I find it problematic. When using Eq. (3.47), it only works when neurons are really dense. Then they claim width has to be small to make Eq. (3.47) big. However, if width is really small, then approximation in Eq. (3.47) won't hold any more.\n",
    "\n",
    "For Eq. (3.48), check errata. \"both expressions should be divided rather than multiplied by $D$\".\n",
    "\n",
    "### pp. 112-113 optimal discrimination.\n",
    "\n",
    "eq. (3.49) has $\\Delta s$ because that $d'$ framework requries two distinct stimuli for doing classification. It's not a framework for evaluating regression.\n",
    "\n",
    "I believe Figure 3.12 assumes many things. Check original paper [A theory for the use of visual orientation information which exploits the columnar structure of striate cortex](https://doi.org/10.1007/BF00363954).\n",
    "\n",
    "1. the y axis values of triangles are real. x axis values are based on heuristic.\n",
    "2. for the solid curve, it's based on modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "### A\n",
    "\n",
    "skipped. Notice that ratio test is most powerful (biggest $\\beta$) given fixed false alarm rate ($\\alpha$).\n",
    "\n",
    "### B\n",
    "\n",
    "skipped."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

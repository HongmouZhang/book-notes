{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Model fitting\n",
    "\n",
    "### pp. 255\n",
    "\n",
    "> let us set $w_C=0$, to ensure identifiability.\n",
    "\n",
    "This is where Murphy sucks. Assuming too much from readers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Bayesian logistic regression\n",
    "\n",
    "> this canot be done exactly, since there is no convenient conjugate prior for logistic regression.\n",
    "\n",
    "I think here we are talking about prior on $w$. For Bernoulli or categorical distribution, there exists prior.\n",
    "\n",
    "One interesting question about conjugate prior is that, for exponential family, we can either use canonical parameters or some more conventional \"normal\" parameters). But when talking about prior, whose prior we are talking about? Seems that for both parameterization, we have priors. See 9.2.5.2 of MLAPP. I think these two priors are the same most of the time, see my special note on exponential family.\n",
    "\n",
    "Much of material covered here is also discussed in PRML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Online learning and stochastic optimization\n",
    "\n",
    "I think it's better to check out materials on deep learning optimization, which uses stochastic optimization a lot.\n",
    "\n",
    "One word about Robbins-Monro. According to [Wikipedia](https://en.wikipedia.org/wiki/Stochastic_approximation#Subsequent_developments_and_Polyak-Ruppert_Averaging), it doesn't work in practice, maybe the constant term or \"burn-in\" time for the convergence is too big.\n",
    "\n",
    "In 8.5.5, the author argues that using Bayesian approach might be better and even quicker than SGD. Sadly, implementation of this in Deep Learning era is probably difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 Generative vs discriminative classifiers.\n",
    "\n",
    "In 8.6.3.3, there's a probabilistic extension to FLDA. Just ignore it, as we are in the Deep Learning era..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

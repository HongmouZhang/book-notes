{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Summarizing posterior distributions\n",
    "\n",
    "### pp. 153\n",
    "\n",
    "5.2.1.4 **MAP estimation is not invariant to reparameterization** points out a basic problem of MAP. When we do MAP, we need to specify our prior on each parameter, and the prior puts different amount of belief for each possible value of the parameter. However, under different parameterizations, as shown in top of pp. 154, one can obtain arbitrary prior, and such arbitrary prior is able to distort our final posterior.\n",
    "\n",
    "\n",
    "This is not a problem for MLE, since when doing MLE, we are maximizing likelihood, which is probability for data, but only a function for parameter, but when we are doing MAP, we are maximizing the conditional probability of parameter given data, and this is a probability on paramter, so parameter transformation will induce some Jacobian terms to redistribute measure in the parameter space. This highlighted the fact that **likelihood is probability for data, and function for parameter, and prior is probability for parameter**.\n",
    "\n",
    "This is not a problem for full Bayesian approach, according to the book. Although I'm not sure what this means exactly, it seems true. For example, consider the example in Eq. (5.3), before transformation, the 50% quantile of prior is $\\mu=0.5$. After transformation, you can easily compute that 50% quantile is $\\theta=\\sqrt{2}/2$, which corresponds to $\\mu=0.5$.\n",
    "\n",
    "### pp. 154\n",
    "\n",
    "Credible Interval is not Confidence Interval. <http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/> gives a very good example of it, and it brings some interpretation problem when using p-value.\n",
    "\n",
    "### pp. 157\n",
    "\n",
    "This Amazon example is great for Bayesian technique. For Figure 5.5(b), Central Interval is given, not HPD, as claimed by the text just above 5.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Bayesian model selection\n",
    "\n",
    "### pp. 158\n",
    "\n",
    "> Another way to understand the Bayesian Occam's razor effect is to note that probabbilities must sum to one. ...\n",
    "\n",
    "This is a very good explanation why Larger model may not necessarily have large evidence. But as said in Bishop's book, for Bayesian model comparison to work, you must have the correct model in the first place. (pp. 165, PRML).\n",
    "\n",
    "### pp. 163\n",
    "\n",
    "According to 5.3.2.4, BIC is motivated by computing evidence. In pp. 164, it says that BIC is related to MDL, and AIC works similarly as BIC, although it can't be derived from a Bayesian perspective.\n",
    "\n",
    "### pp. 164\n",
    "\n",
    "> Fortunately, the higher up we go in the Bayesian hierarchy, the less sensitive are the results to the prior settings.\n",
    "\n",
    "I think the more layers of prior you have, the more flat is the prior, maybe. That's why your results is not sensitive, because the prior becomes more and more uninformative.\n",
    "\n",
    "### pp. 166\n",
    "\n",
    "> since the absolute scale is irrelevant.\n",
    "\n",
    "I don't think so, since $p(D\\mid M_0)$ is a constant. Shifting or scaling $p(D\\mid M_1)$ by some constant may make one always reject or accept one model.\n",
    "\n",
    "As for 5.3.4 Jefferys-Lindley paradox, I prefer reading wikipedia directly (<https://en.wikipedia.org/wiki/Lindley's_paradox>). Essentially flat priors can sometimes assign too little evidence to the data to give some surprising results. I think the example given in this book is technically wrong in some sense. For example, I'm not sure if you can make sure $\\ell_i$ are well defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Priors\n",
    "\n",
    "### pp. 168\n",
    "\n",
    "Jefferys priors is interesting, so is Haldane prior. <http://stats.stackexchange.com/questions/238089/beta-distribution-on-flipping-a-coin/238180> (a copy available at [here](./chapter05/beta_distribution.htm)) gives some detailed description of these. For example, what do we mean when we say that Haldane is improper.\n",
    "\n",
    "### pp. 170\n",
    "\n",
    "Robust priors. Essentialy, when using heavy tailed priors, posteriors won't be affected by prior mean too much. BTW, here the Cauchy prior's parameterization $\\mathcal{T}(\\theta\\mid 0,1,1)$ is defined in terms of t-distribution. Check Chapter 2 of MLAPP.\n",
    "\n",
    "### pp. 171\n",
    "\n",
    "Mixture of conjugate priors. Never heard of this. But its properties sound really nice. No idea why I haven't heard of it before. Maybe it's because it's not expoenential family? Well I think it's because it requires computing marginal likelihood, and according to Section 5.3.2, it's not always tractable to compute that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Hierarchical Bayes\n",
    "\n",
    "Essentially when you have prior over prior, you have hierarchical Bayes.\n",
    "\n",
    "The example used shows the power of hierarchical Bayes: statistical strength sharing among different populations. The key is, whenever you want to pool the data of several populations together, maing their parameters sampled from some common parameter distribution, and make that parameter distribution hidden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Empirical Bayes\n",
    "\n",
    "The table in pp. 175 gives a good summary of relationships of different inference methods ML, MAP, ML-II, MAP-II, and full Bayes. No idea why \"empirical Bayes violates the principle that the prior should be chosen independently of the data\", but I just consider it a cheap way to compute hyper parameter in a empirical Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Bayesian decision theory\n",
    "\n",
    "### pp. 181\n",
    "\n",
    "Eq. (5.108) is just because that expectation is a linear operation so you can take $x$ out.\n",
    "\n",
    "### pp. 182\n",
    "\n",
    "Eq. (5.109) is just another way of writing Eq. (5.98) with a prior term on $x$ and marginalized out, and the data distribution parameterized by $\\theta$. I think it's essentially the same as Eq. (5.98), except that in Eq. (5.98), the $\\theta$ is marginalized out, and that form deals with each $x$ separately.\n",
    "\n",
    "### pp. 184\n",
    "\n",
    "5.7.2.2 gives reason why we don't use ROC in object detection. This is because here negative is ill-defined.\n",
    "\n",
    "### pp. 185\n",
    "\n",
    "5.7.2.3 gives reason why F score uses harmonic mean, not arithmetic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

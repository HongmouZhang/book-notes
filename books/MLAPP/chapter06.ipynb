{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Sampling distribution of an estimator\n",
    "\n",
    "### pp. 196\n",
    "\n",
    "Here the large sample theory of MLE is not very clearly written, and I believe some definitions, such as the one below Eq. (6.4), is just wrong. Instead, for these properties, check Section 7.4 (Information and Efficiency) of [Modern Mathematical Statistics with Applications 2nd edition](dx.doi.org/10.1007/978-1-4614-0391-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Frequentist decision theory\n",
    "\n",
    "### pp. 197\n",
    "\n",
    "In Eq. (6.9) and Eq. (6.10), $L(\\theta, a)$ is defined as in (5.109), that is, the expected error over the distribution generated by $\\theta$, using decision function $a(x)$.\n",
    "\n",
    "The footnote 3 here is very insightful about why using frequentist approaches has limitations.\n",
    "\n",
    "> In practice, the frequentist approach is usually only applied to one-shot statistical decision problems — such as classification, regression and parameter estimation — since its non-constructive nature makes it difficult to apply to sequential decision problems, which adapt to data online.\n",
    "\n",
    "6.3.1 is just the Bayes decision rule, minimizing posterior loss for each input. Here, we call $p(\\theta)$ a prior. But in Eq. (5.110), the prior has incorporated the data, and the form is the same as here.\n",
    "\n",
    "6.3.2 Minimax is really pessimistic. It sounds to me like worst case analysis. Which is probably useless with out adversary.\n",
    "\n",
    "### pp. 201\n",
    "\n",
    "6.3.3.2 shows some peculiarities of MLE estimators. But I think in practice it's not a big problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Desirable properties of estimators\n",
    "\n",
    "### pp. 207\n",
    "\n",
    "6.4.4.3 shows that bias-variance trade off analysis actually doesn't work for classification. Check the Hastie 2009 for detail. Still, I think bias-variance trade off is totally wrong for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Pathologies of frequentist statistics\n",
    "\n",
    "### pp. 216\n",
    "\n",
    "Very interesting argument saying that p-value depends on stopping rule!\n",
    "\n",
    "### pp. 217\n",
    "\n",
    "6.6.3 seems to suggest frequentist approaches actually depend on unseen data, which is also mentioned in [A practical solution to the pervasive problems of p values](http://www.ejwagenmakers.com/2007/pValueProblems.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

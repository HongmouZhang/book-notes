{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a collection of additional notes for chapter 4. Most of time, it should be sufficient to check out `02_Markov_Random_Fields.ipynb` in the dedicated folder for graphical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Parameterization\n",
    "### pp. 112\n",
    "> Note the contrast to the effect of conditioning in a Bayesian network: Here, conditioning on a context u only eliminates edges from the graph; in a Bayesian network, conditioning on evidence can activate a v-structure, creating new dependencies.\n",
    "\n",
    "This (Proposition 4.2) nice property of MRF can be shown. Initially, our distribution is a product of max cliques, some involving $u$, some not. When eliminating a node $u$, all cliques not involving $u$ are not affected, and all cliques involving $u$ have reduced their sizes by 1. It's trivial to check that those new cliques, whether they are affected or not, are cliques in $H[u]$. Thus, this new conditioned distribution, which is a product of cliques over $H[u]$, can be represented by $H[u]$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Markov Network Independencies\n",
    "\n",
    "### pp. 115 Def 4.9\n",
    "\n",
    "When taking about I-map for a MRF, this book is talking about global dependencies, although as later shown, for positive distributions, local, pairwise, and global are all the same.\n",
    "\n",
    "### pp. 132\n",
    "\n",
    "> for positive distributions, all four conditions -- factorization and the three types of Markov assumptions -- are all equivalent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Bayesian Networks and Markov Networks\n",
    "\n",
    "### pp 139\n",
    "\n",
    "> Because any nontriangulated loop of length at least 4 in a Bayesian network graph necessarily contains an immorality.\n",
    "\n",
    "Proof of this can be seen in `02_Markov_Random_Fields.ipynb`. The contrapositive of this means that for BN, moral graph be must be chordal. This is consistent with the fact that every moral BN can be converted to MRF without adding edge.\n",
    "\n",
    "### pp. 140\n",
    "\n",
    "Here we have definition of clique tree (junction tree in many other sources). But I think it's ill defined. For example, just above the definition 4.17, we have \"Each edge decomposes $X$ into three disjoint sets ...\". But without explicit mentioning of running intersection property, it's hard for me to see how you can make sure variables at two sides of the tree don't overlap.\n",
    "\n",
    "I think it would be better to define junction tree (clique tree here) just as all other materials, using RIP plus tree structure plus family preservation, and specify this sepset separation property as a corollary (one direction of Thm 10.2), rather than a definition of junction tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
